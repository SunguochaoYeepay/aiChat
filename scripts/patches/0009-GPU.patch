From 99672e1b8eaab5699a310668c085392f983fb2e6 Mon Sep 17 00:00:00 2001
From: Design Helper Developer <user@example.com>
Date: Mon, 5 May 2025 10:28:51 +0800
Subject: [PATCH 9/9] =?UTF-8?q?=E4=BF=AE=E5=A4=8D=E5=90=AF=E5=8A=A8GPU?=
 =?UTF-8?q?=E9=97=AE=E9=A2=98?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 admin_system/api/urls.py             |   2 +
 admin_system/api/views.py            |  20 +-
 admin_system/core/model_service.py   |  20 +-
 admin_system/start_with_chat_env.bat |  16 ++
 docs/api_reference.md                | 262 +++++++++++++++++++++++++++
 5 files changed, 318 insertions(+), 2 deletions(-)
 create mode 100644 admin_system/start_with_chat_env.bat
 create mode 100644 docs/api_reference.md

diff --git a/admin_system/api/urls.py b/admin_system/api/urls.py
index 08a8fcb..f399bef 100644
--- a/admin_system/api/urls.py
+++ b/admin_system/api/urls.py
@@ -7,6 +7,8 @@ from django.urls import path
 from . import views
 
 urlpatterns = [
+    # 首页路由
+    path('', views.index_view, name='index'),
     # 原有API接口
     path('analyze', views.analyze_image, name='api_analyze_image'),
     path('v1/chat/completions', views.chat_completions, name='api_chat_completions'),
diff --git a/admin_system/api/views.py b/admin_system/api/views.py
index 304de0b..3926adb 100644
--- a/admin_system/api/views.py
+++ b/admin_system/api/views.py
@@ -5,7 +5,7 @@ API视图函数 - 提供与原系统兼容的API接口
 """
 import json
 import time
-from django.http import JsonResponse
+from django.http import JsonResponse, HttpResponse
 from django.views.decorators.csrf import csrf_exempt
 from django.views.decorators.http import require_http_methods
 
@@ -16,6 +16,24 @@ from core.model_service import get_service_status as get_model_status
 from management.models import KnowledgeBase
 from knowledge_base.services import search_knowledge_base as kb_vector_search
 
+def index_view(request):
+    """
+    首页视图函数
+    
+    处理根路径"/"的请求
+    """
+    return HttpResponse(
+        '<h1>设计助手API服务</h1>'
+        '<p>API服务已正常运行。</p>'
+        '<p>可用API接口:</p>'
+        '<ul>'
+        '<li>/api/analyze - 图像分析接口</li>'
+        '<li>/api/v1/chat/completions - 聊天完成接口</li>'
+        '<li>/api/search - 知识库搜索接口</li>'
+        '<li>/api/status - 服务状态接口</li>'
+        '</ul>'
+    )
+
 @csrf_exempt
 @require_http_methods(["POST"])
 def analyze_image(request):
diff --git a/admin_system/core/model_service.py b/admin_system/core/model_service.py
index b85bc3d..d1ec8be 100644
--- a/admin_system/core/model_service.py
+++ b/admin_system/core/model_service.py
@@ -54,6 +54,17 @@ def init_model(model_path=None, device=None, precision=None):
         _is_loading = True
         
         try:
+            # 详细检查CUDA是否可用
+            cuda_available = torch.cuda.is_available()
+            logger.info(f"CUDA是否可用: {cuda_available}")
+            if cuda_available:
+                try:
+                    cuda_device_count = torch.cuda.device_count()
+                    cuda_device_name = torch.cuda.get_device_name(0) if cuda_device_count > 0 else "未知"
+                    logger.info(f"CUDA设备数量: {cuda_device_count}, 设备名称: {cuda_device_name}")
+                except Exception as e:
+                    logger.warning(f"获取CUDA设备信息时出错: {str(e)}")
+            
             # 如果没有提供配置，则使用默认值或从数据库获取
             if not model_path:
                 from management.models import ModelConfig
@@ -70,13 +81,20 @@ def init_model(model_path=None, device=None, precision=None):
                     precision = getattr(settings, 'DEFAULT_PRECISION', 'float16')
             
             # 检查CUDA是否可用，如果不可用则回退到CPU
-            if device == 'cuda' and not torch.cuda.is_available():
+            if device == 'cuda' and not cuda_available:
                 logger.warning("CUDA不可用，回退到CPU模式运行")
                 device = 'cpu'
                     
             logger.info(f"开始加载模型: {model_path}")
             logger.info(f"设备: {device}, 精度: {precision}")
             
+            # 尝试查找非量化模型路径
+            if device == 'cpu' and ('Int4' in model_path or 'Int8' in model_path):
+                non_quantized_path = model_path.replace("-Int4", "").replace("-Int8", "")
+                if os.path.exists(non_quantized_path):
+                    logger.info(f"在CPU模式下使用非量化模型: {non_quantized_path}")
+                    model_path = non_quantized_path
+            
             # 记录加载开始时间
             load_start = time.time()
             
diff --git a/admin_system/start_with_chat_env.bat b/admin_system/start_with_chat_env.bat
new file mode 100644
index 0000000..fab2052
--- /dev/null
+++ b/admin_system/start_with_chat_env.bat
@@ -0,0 +1,16 @@
+@echo off
+echo 正在使用chat_env环境启动Django服务...
+
+cd %~dp0
+cd ..
+
+call chat_env\Scripts\activate.bat
+
+echo 正在检查CUDA可用性...
+python -c "import torch; print('CUDA可用:', torch.cuda.is_available())"
+
+echo 启动Django服务器...
+cd admin_system
+python manage.py runserver 0.0.0.0:8000
+
+pause 
\ No newline at end of file
diff --git a/docs/api_reference.md b/docs/api_reference.md
new file mode 100644
index 0000000..2a50ee8
--- /dev/null
+++ b/docs/api_reference.md
@@ -0,0 +1,262 @@
+# 设计助手后端API接口文档
+
+## 基本信息
+
+- **服务地址**: http://127.0.0.1:8000
+- **认证方式**: 无需认证
+
+## HTTP API接口列表
+
+| 接口路径 | 方法 | 描述 |
+|---------|------|------|
+| `/api/analyze` | POST | 图像分析接口，接收图像和查询文本，返回分析结果 |
+| `/api/v1/chat/completions` | POST | 聊天完成接口，兼容OpenAI格式，支持流式响应 |
+| `/api/search` | POST | 知识库搜索接口，根据查询文本返回相关知识条目 |
+| `/api/status` | GET | 服务状态接口，返回系统和模型的当前状态 |
+
+## 详细API说明
+
+### 1. 图像分析API
+
+分析上传的图像并回答相关问题。
+
+- **URL**: `/api/analyze`
+- **方法**: POST
+- **Content-Type**: application/json
+
+**请求参数**:
+
+```json
+{
+  "image_base64": "图像的base64编码",
+  "query": "关于图像的问题"
+}
+```
+
+**返回结果**:
+
+```json
+{
+  "result": "分析结果文本",
+  "processing_time": "处理时间(秒)",
+  "boxed_image_url": "带边界框的图像URL（如果有）"
+}
+```
+
+**示例**:
+
+```javascript
+// 前端示例代码
+const response = await fetch('http://127.0.0.1:8000/api/analyze', {
+  method: 'POST',
+  headers: {
+    'Content-Type': 'application/json',
+  },
+  body: JSON.stringify({
+    image_base64: imageBase64String,
+    query: "这张设计图有什么问题？"
+  }),
+});
+const data = await response.json();
+```
+
+### 2. 聊天API
+
+与AI助手进行对话，支持多轮对话。
+
+- **URL**: `/api/v1/chat/completions`
+- **方法**: POST
+- **Content-Type**: application/json
+
+**请求参数**:
+
+```json
+{
+  "messages": [
+    {"role": "user", "content": "第一个问题"},
+    {"role": "assistant", "content": "AI的回复"},
+    {"role": "user", "content": "后续问题"}
+  ],
+  "stream": false
+}
+```
+
+参数说明:
+- `messages`: 对话历史记录，包含用户和助手的消息
+- `stream`: 是否使用流式返回，设为true时支持实时返回
+
+**返回结果**:
+
+```json
+{
+  "id": "chatcmpl-123",
+  "object": "chat.completion",
+  "created": 1677858242,
+  "model": "qwen-vl-chat",
+  "choices": [
+    {
+      "index": 0,
+      "message": {
+        "role": "assistant",
+        "content": "AI助手的回复内容"
+      },
+      "finish_reason": "stop"
+    }
+  ],
+  "usage": {
+    "prompt_tokens": 56,
+    "completion_tokens": 31,
+    "total_tokens": 87
+  }
+}
+```
+
+**示例**:
+
+```javascript
+// 前端示例代码
+const response = await fetch('http://127.0.0.1:8000/api/v1/chat/completions', {
+  method: 'POST',
+  headers: {
+    'Content-Type': 'application/json',
+  },
+  body: JSON.stringify({
+    messages: [
+      {role: "user", content: "分析这个设计的排版有什么问题?"}
+    ],
+    stream: false
+  }),
+});
+const data = await response.json();
+```
+
+### 3. 知识库搜索API
+
+在知识库中搜索相关内容。
+
+- **URL**: `/api/search`
+- **方法**: POST
+- **Content-Type**: application/json
+
+**请求参数**:
+
+```json
+{
+  "query": "搜索关键词",
+  "top_k": 5
+}
+```
+
+参数说明:
+- `query`: 搜索查询文本
+- `top_k`: 返回结果数量，默认为5
+
+**返回结果**:
+
+```json
+{
+  "results": [
+    {
+      "content": "搜索到的内容1",
+      "score": 0.89,
+      "source": "来源文档"
+    },
+    {
+      "content": "搜索到的内容2",
+      "score": 0.75,
+      "source": "来源文档"
+    }
+  ],
+  "processing_time": "0.12秒"
+}
+```
+
+**示例**:
+
+```javascript
+// 前端示例代码
+const response = await fetch('http://127.0.0.1:8000/api/search', {
+  method: 'POST',
+  headers: {
+    'Content-Type': 'application/json',
+  },
+  body: JSON.stringify({
+    query: "设计原则",
+    top_k: 3
+  }),
+});
+const data = await response.json();
+```
+
+### 4. 服务状态API
+
+获取服务器和模型的当前状态。
+
+- **URL**: `/api/status`
+- **方法**: GET
+
+**返回结果**:
+
+```json
+{
+  "status": "running",
+  "model": "qwen-vl-chat",
+  "gpu_usage": {
+    "memory_used": "4.2 GB",
+    "memory_total": "12 GB",
+    "utilization": "32%"
+  },
+  "uptime": "2天13小时45分钟"
+}
+```
+
+**示例**:
+
+```javascript
+// 前端示例代码
+const response = await fetch('http://127.0.0.1:8000/api/status');
+const data = await response.json();
+```
+
+## WebSocket接口
+
+系统支持WebSocket连接，用于实时通信：
+
+| 接口 | 描述 |
+|------|------|
+| `ws://127.0.0.1:8000/ws/chat/` | 聊天WebSocket接口，支持实时对话 |
+| `ws://127.0.0.1:8000/ws/analyze/` | 图像分析WebSocket接口，支持实时图像分析 |
+
+### WebSocket使用示例
+
+```javascript
+// 聊天WebSocket示例
+const chatSocket = new WebSocket('ws://127.0.0.1:8000/ws/chat/');
+
+chatSocket.onopen = () => {
+  console.log('WebSocket连接已建立');
+  chatSocket.send(JSON.stringify({
+    message: "你好，请分析这个设计",
+    type: "message"
+  }));
+};
+
+chatSocket.onmessage = (e) => {
+  const data = JSON.parse(e.data);
+  console.log('收到消息:', data);
+};
+```
+
+## 错误处理
+
+所有API在发生错误时会返回相应的HTTP状态码和错误信息：
+
+```json
+{
+  "error": "错误描述信息"
+}
+```
+
+常见错误状态码：
+- 400: 请求参数错误
+- 404: 请求的资源不存在 
\ No newline at end of file
-- 
2.49.0.windows.1

